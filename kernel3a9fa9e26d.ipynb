{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Import tensorflow for later use in the NN\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\n\n# Upload the data with pandas\nfull_train_data = pd.read_csv('/kaggle/input/titanic/train.csv')\nfull_train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the random module. We will need it for randomly initialising the NN and also randomly splitting the data into training and cross-validation\nimport random\n\n# Randomly permute the passanger order\nrand_passenger = [x for x in range(891)]\nrandom.shuffle(rand_passenger)\n\n# Split into train_data, cv_data and test_data at a ratio of roughly 3:1:1 resp.\npassengers_train = rand_passenger[:-178]\n# passengers_cv = rand_passenger[-356:-178]\npassengers_cv = rand_passenger[-178:]\n\ntrain_data = full_train_data.loc[passengers_train,:]\ncv_data = full_train_data.loc[passengers_cv,:]\n# test_data = full_train_data.loc[passengers_test,:]\n\ntrain_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we will use a data set that has the Ticket, Cabin, Name,, PassengerId and Embarked removed\n# It seems likely that these will not play a role in determining whether a passenger survived but we can check later to see if we were wrong\n\ntrain_data_1 = train_data[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare']]\ncv_data_1 = cv_data[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare']]\n# test_data_1 = test_data[['Survived','Pclass','Sex','Age','SibSp','Parch','Fare']]\n\ntrain_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here we will mean normalise the age and the fare. Everything else is roughly on the same range\nage_mean = train_data_1['Age'].mean()\nage_range = train_data_1['Age'].max() - train_data_1['Age'].min()\n\nfare_mean = train_data_1['Fare'].mean()\nfare_range = train_data_1['Fare'].max()-train_data_1['Fare'].min()\n\n# The normalised training data is\ntrain_data_1.loc[:,'Fare'] = (train_data_1.loc[:,'Fare'] - fare_mean)/fare_range\ntrain_data_1.loc[(pd.notnull(train_data_1['Age'])),'Age'] = (train_data_1.loc[(pd.notnull(train_data_1['Age'])),'Age'] - age_mean)/age_range\n\ntrain_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We also need to normalise the test and cv data\n# We do this with the same mean and average calculated in the training data\n\n# The normalised test data is\n# test_data_1.loc[:,'Fare'] = (test_data_1.loc[:,'Fare'] - fare_mean)/fare_range\n# test_data_1.loc[(pd.notnull(test_data_1['Age'])),'Age'] = (test_data_1.loc[(pd.notnull(test_data_1['Age'])),'Age'] -age_mean)/age_range\n\n# The normalised cv data is\ncv_data_1.loc[:,'Fare'] = (cv_data_1.loc[:,'Fare'] - fare_mean)/fare_range\ncv_data_1.loc[(pd.notnull(cv_data_1['Age'])),'Age'] = (cv_data_1.loc[(pd.notnull(cv_data_1['Age'])),'Age'] - age_mean)/age_range\n\n# test_data_1,\ncv_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some of the ages are missing. We need to find a way to replace them\n# We will replace NaN with the average age (rounded) for that sex and Pclass\n# We will just do the replacement with the train_data average rather than the full_train_data average\n\n# The following splits the data into those with no age and those with age\nno_age =  train_data_1[pd.isnull(train_data_1['Age'])]\nwith_age = train_data_1[pd.notnull(train_data_1['Age'])]\n\n\n# No we calculate the mean age of people in each class and sex\nwith_age_1m = with_age[(with_age['Sex'] == 'male') & (with_age['Pclass'] == 1)]\naverage_1m = with_age_1m['Age'].mean()\n\nwith_age_2m = with_age[(with_age['Sex'] == 'male') & (with_age['Pclass'] == 2)]\naverage_2m = with_age_2m['Age'].mean()\n\nwith_age_3m = with_age[(with_age['Sex'] == 'male') & (with_age['Pclass'] == 3)]\naverage_3m = with_age_3m['Age'].mean()\n\nwith_age_1f = with_age[(with_age['Sex'] == 'female') & (with_age['Pclass'] == 1)]\naverage_1f = with_age_1f['Age'].mean()\n\nwith_age_2f = with_age[(with_age['Sex'] == 'female') & (with_age['Pclass'] == 2)]\naverage_2f = with_age_2f['Age'].mean()\n\nwith_age_3f = with_age[(with_age['Sex'] == 'female') & (with_age['Pclass'] == 3)]\naverage_3f = with_age_3f['Age'].mean()\n\naverage_1m, average_2m, average_3m, average_1f, average_2f, average_3f","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We replace all the NaN with the average\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'male') & (train_data_1['Pclass']==1),'Age'] = average_1m\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'male') & (train_data_1['Pclass']==2),'Age'] = average_2m\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'male') & (train_data_1['Pclass']==3),'Age'] = average_3m\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'female') & (train_data_1['Pclass']==1),'Age'] = average_1f\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'female') & (train_data_1['Pclass']==2),'Age'] = average_2f\ntrain_data_1.loc[(pd.isnull(train_data_1['Age'])) & (train_data_1['Sex'] == 'female') & (train_data_1['Pclass']==3),'Age'] = average_3m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We need to do the same with the test data and the cv data\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'male') & (test_data_1['Pclass']==1),'Age'] = average_1m\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'male') & (test_data_1['Pclass']==2),'Age'] = average_2m\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'male') & (test_data_1['Pclass']==3),'Age'] = average_3m\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'female') & (test_data_1['Pclass']==1),'Age'] = average_1f\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'female') & (test_data_1['Pclass']==2),'Age'] = average_2f\n# test_data_1.loc[(pd.isnull(test_data_1['Age'])) & (test_data_1['Sex'] == 'female') & (test_data_1['Pclass']==3),'Age'] = average_3m\n\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'male') & (cv_data_1['Pclass']==1),'Age'] = average_1m\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'male') & (cv_data_1['Pclass']==2),'Age'] = average_2m\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'male') & (cv_data_1['Pclass']==3),'Age'] = average_3m\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'female') & (cv_data_1['Pclass']==1),'Age'] = average_1f\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'female') & (cv_data_1['Pclass']==2),'Age'] = average_2f\ncv_data_1.loc[(pd.isnull(cv_data_1['Age'])) & (cv_data_1['Sex'] == 'female') & (cv_data_1['Pclass']==3),'Age'] = average_3m","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now want to change the strings male/female into something numerical\n# I will take the Sex column and split it into 2 boolean columns male/female consisting of 1's and 0's\n\n# For train data\nis_male_train = (train_data_1['Sex']=='male')\nis_female_train = (train_data_1['Sex']=='female')\n\n# For test data\n# is_male_test = (test_data_1['Sex']=='male')\n# is_female_test = (test_data_1['Sex']=='female')\n\n# For cv data\nis_male_cv = (cv_data_1['Sex']=='male')\nis_female_cv = (cv_data_1['Sex']=='female')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We now want to join them all together (c stands for cleaned)\n\n# The cleaned training data is\nhold = pd.concat(\n    [train_data_1,\n     pd.Series(data = is_male_train*1, index = is_male_train.index, name = 'Male'), \n     pd.Series(data=is_female_train*1,index = is_female_train.index,name='Female')],\n    axis=1)\nc_train_data_1 = hold[['Survived','Pclass','Age','SibSp','Parch','Fare','Male','Female']]\n\n# The cleaned test data is\n# hold = pd.concat(\n#     [test_data_1,\n#      pd.Series(data = is_male_test*1, index = is_male_test.index, name = 'Male'),\n#      pd.Series(data=is_female_test*1,index = is_female_test.index,name='Female')],\n#     axis=1)\n# c_test_data_1 = hold[['Survived','Pclass','Age','SibSp','Parch','Fare','Male','Female']]\n\n# the cleaned cv data is\nhold = pd.concat(\n    [cv_data_1,\n     pd.Series(data = is_male_cv*1, index = is_male_cv.index, name = 'Male'),\n     pd.Series(data=is_female_cv*1,index = is_female_cv.index,name='Female')],\n    axis=1)\nc_cv_data_1 = hold[['Survived','Pclass','Age','SibSp','Parch','Fare','Male','Female']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_train_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are now in a position to run the NN on this training data\n# We will use the tensorflow to build and run the NN\n\nmodel_1 = keras.Sequential([\n    keras.Input(shape = (7,)),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(5,activation = 'relu'),\n    keras.layers.Dense(5,activation = 'relu'),\n    keras.layers.Dense(1, activation = 'sigmoid')\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The following compiles the model and determines the optimization algorithm as well as the metric to determine how well the model has done\n\nmodel_1.compile(optimizer='adam',\n               loss = 'mean_squared_error',\n               metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = c_train_data_1[['Pclass','Age','SibSp','Parch','Fare','Male','Female']].astype('float32')\ny = c_train_data_1['Survived'].astype('float32')\n\nX_val = c_cv_data_1[['Pclass','Age','SibSp','Parch','Fare','Male','Female']].astype('float32')\ny_val = c_cv_data_1['Survived'].astype('float32')\n\nmodel_1.fit(X,y, epochs=70,validation_data = (X_val,y_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(model_1.history.history['accuracy'])\nplt.plot(model_1.history.history['val_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c_train_data_2 = c_train_data_1[['Survived','Pclass','Age','Male','Female']]\nc_cv_data_2 = c_cv_data_1[['Survived','Pclass','Age','Male','Female']]\nX = c_train_data_2[['Pclass','Age','Male','Female']].astype('float32')\ny = c_train_data_2[['Survived']].astype('float32')\n\nX_val = c_cv_data_2[['Pclass','Age','Male','Female']].astype('float32')\ny_val = c_cv_data_2[['Survived']].astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_2 = keras.Sequential([\n    keras.Input(shape = (4,)),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(10,activation = 'relu'),\n    keras.layers.Dense(1, activation = 'sigmoid')\n])\n\nmodel_2.compile(optimizer='adam',\n               loss = 'mean_squared_error',\n               metrics = ['accuracy','recall'])\n\nmodel_2.fit(X,y, epochs=50,validation_data = (X_val,y_val))\n\nplt.plot(model_2.history.history['accuracy'])\nplt.plot(model_2.history.history['val_accuracy'])\nplt.plot(model_2.history.history['recall'])\nplt.plot(model_2.history.history['val_recall'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}